{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "src1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download Repo"
      ],
      "metadata": {
        "id": "QOKDVLuB_eIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! git clone https://github.com/FerdiantJoshua/question-generator"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-01-21T15:16:34.376632Z",
          "iopub.execute_input": "2022-01-21T15:16:34.377466Z",
          "iopub.status.idle": "2022-01-21T15:16:43.162638Z",
          "shell.execute_reply.started": "2022-01-21T15:16:34.377372Z",
          "shell.execute_reply": "2022-01-21T15:16:43.161492Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2rC0BJBSa0m",
        "outputId": "e53be29d-d6df-4790-9c08-513341007b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'question-generator'...\n",
            "remote: Enumerating objects: 480, done.\u001b[K\n",
            "remote: Counting objects: 100% (422/422), done.\u001b[K\n",
            "remote: Compressing objects: 100% (243/243), done.\u001b[K\n",
            "remote: Total 480 (delta 254), reused 330 (delta 172), pack-reused 58\u001b[K\n",
            "Receiving objects: 100% (480/480), 47.27 MiB | 22.15 MiB/s, done.\n",
            "Resolving deltas: 100% (273/273), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilize GPU"
      ],
      "metadata": {
        "id": "h16-8QME_b1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfIu61WJ_Z2t",
        "outputId": "4ef5f317-bfac-4351-9988-4c7314913d00"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ganti isi requirements.txt yang tidak ada line genshim nya "
      ],
      "metadata": {
        "id": "niuGNlmqSa0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"requirements.txt\", \"w\")\n",
        "f.write(\"\"\"boto==2.49.0\n",
        "boto3==1.12.20\n",
        "botocore==1.15.20\n",
        "certifi==2019.11.28\n",
        "chardet==3.0.4\n",
        "cycler==0.10.0\n",
        "docutils==0.15.2\n",
        "fuzzywuzzy==0.18.0\n",
        "idna==2.9\n",
        "jmespath==0.9.5\n",
        "kiwisolver==1.1.0\n",
        "matplotlib==3.2.0\n",
        "nltk==3.4.5\n",
        "numpy==1.18.1\n",
        "OpenNMT-py==1.1.1\n",
        "pandas==1.0.1\n",
        "Pillow==7.0.0\n",
        "pyparsing==2.4.6\n",
        "python-dateutil==2.8.1\n",
        "python-Levenshtein==0.12.0\n",
        "pytz==2019.3\n",
        "requests==2.23.0\n",
        "s3transfer==0.3.3\n",
        "scipy==1.4.1\n",
        "six==1.14.0\n",
        "smart-open==1.9.0\n",
        "torch==1.4.0\n",
        "torchvision==0.5.0\n",
        "Unidecode==1.1.1\n",
        "urllib3==1.25.8\n",
        "git+https://github.com/Maluuba/nlg-eval.git@master\n",
        "\"\"\")\n",
        "f.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-21T15:16:43.164622Z",
          "iopub.execute_input": "2022-01-21T15:16:43.164877Z",
          "iopub.status.idle": "2022-01-21T15:16:43.170370Z",
          "shell.execute_reply.started": "2022-01-21T15:16:43.164850Z",
          "shell.execute_reply": "2022-01-21T15:16:43.169763Z"
        },
        "trusted": true,
        "id": "z8bwnnBnSa0r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-21T15:16:43.171541Z",
          "iopub.execute_input": "2022-01-21T15:16:43.171789Z",
          "iopub.status.idle": "2022-01-21T15:20:01.775177Z",
          "shell.execute_reply.started": "2022-01-21T15:16:43.171762Z",
          "shell.execute_reply": "2022-01-21T15:20:01.774111Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qudbqFtPSa0s",
        "outputId": "fe4f0313-d347-4910-c674-db16b3571be3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Maluuba/nlg-eval.git@master (from -r requirements.txt (line 31))\n",
            "  Cloning https://github.com/Maluuba/nlg-eval.git (to revision master) to /tmp/pip-req-build-hnzn2tna\n",
            "  Running command git clone -q https://github.com/Maluuba/nlg-eval.git /tmp/pip-req-build-hnzn2tna\n",
            "Collecting boto==2.49.0\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting boto3==1.12.20\n",
            "  Downloading boto3-1.12.20-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 43.1 MB/s \n",
            "\u001b[?25hCollecting botocore==1.15.20\n",
            "  Downloading botocore-1.15.20-py2.py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 33.6 MB/s \n",
            "\u001b[?25hCollecting certifi==2019.11.28\n",
            "  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.0.4)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting docutils==0.15.2\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 32.6 MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy==0.18.0\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting idna==2.9\n",
            "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting jmespath==0.9.5\n",
            "  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
            "Collecting kiwisolver==1.1.0\n",
            "  Downloading kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.2.0\n",
            "  Downloading matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 22.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 47.8 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.1\n",
            "  Downloading numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 54.7 MB/s \n",
            "\u001b[?25hCollecting OpenNMT-py==1.1.1\n",
            "  Downloading OpenNMT_py-1.1.1-py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting pandas==1.0.1\n",
            "  Downloading pandas-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 38.4 MB/s \n",
            "\u001b[?25hCollecting Pillow==7.0.0\n",
            "  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 39.0 MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.6\n",
            "  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting python-Levenshtein==0.12.0\n",
            "  Downloading python-Levenshtein-0.12.0.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting pytz==2019.3\n",
            "  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (2.23.0)\n",
            "Collecting s3transfer==0.3.3\n",
            "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (1.4.1)\n",
            "Collecting six==1.14.0\n",
            "  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting smart-open==1.9.0\n",
            "  Downloading smart_open-1.9.0.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 36.8 MB/s \n",
            "\u001b[?25hCollecting Unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 52.6 MB/s \n",
            "\u001b[?25hCollecting urllib3==1.25.8\n",
            "  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 29.2 MB/s \n",
            "\u001b[?25hCollecting psutil>=5.6.2\n",
            "  Downloading psutil-5.9.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.28.5 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3->-r requirements.txt (line 31)) (0.29.26)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3->-r requirements.txt (line 31)) (1.0.2)\n",
            "Collecting gensim~=3.8.3\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting Theano>=0.8.1\n",
            "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.24 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3->-r requirements.txt (line 31)) (4.62.3)\n",
            "Collecting xdg\n",
            "  Downloading xdg-5.1.1-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from kiwisolver==1.1.0->-r requirements.txt (line 11)) (57.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (3.13)\n",
            "Collecting tqdm>=4.24\n",
            "  Downloading tqdm-4.30.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (1.1.4)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (2.7.0)\n",
            "Collecting waitress\n",
            "  Downloading waitress-2.0.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.4.0\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (0.16.0)\n",
            "Collecting pyonmttok==1.*\n",
            "  Downloading pyonmttok-1.30.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3 MB 21.6 MB/s \n",
            "\u001b[?25hCollecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17->nlg-eval==2.3->-r requirements.txt (line 31)) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17->nlg-eval==2.3->-r requirements.txt (line 31)) (1.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (1.43.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (3.1.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->OpenNMT-py==1.1.1->-r requirements.txt (line 15)) (2.0.1)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'python-levenshtein' candidate (version 0.12.0 at https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz#sha256=033a11de5e3d19ea25c9302d11224e1a1898fe5abd23c61c7c360c25195e3eb1 (from https://pypi.org/simple/python-levenshtein/))\n",
            "Reason for being yanked: Insecure, upgrade to 0.12.1\u001b[0m\n",
            "Building wheels for collected packages: nlg-eval, nltk, python-Levenshtein, smart-open, Theano\n",
            "  Building wheel for nlg-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlg-eval: filename=nlg_eval-2.3-py3-none-any.whl size=68175165 sha256=cdfcb1c77afd3f57e4a5bf15157db2453b0f5f973878809d7a1c76631496b43c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bp8faok6/wheels/08/20/df/33ced66932f198c4323042d18ff1c2db9b9716369f0de4afb4\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449920 sha256=736c156c948fe842d9d4b0153a0bf1dd4557d9347588aebf42924b5e86aa60f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp37-cp37m-linux_x86_64.whl size=145906 sha256=ca5dfab874a09afc3b5e9fae611cf5b40b0ac0d39fe044fdf7ce8648fbd8611c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/9b/13/49c281164c37be18343230d3cd0fca29efb23a493351db0009\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-1.9.0-py3-none-any.whl size=73096 sha256=e19001ff32fe60ad8197a893c41c4a84f246bd585bc79db1e2522407c6c11e89\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/f6/d9/49cfa288fb14de91f127fb6f7a5a29f389c9588a41140107d9\n",
            "  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano: filename=Theano-1.0.5-py3-none-any.whl size=2668111 sha256=7120527c533bfb510226fc313d808913ba444cade3393a39fb92920b5e64e311\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/68/6f/745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n",
            "Successfully built nlg-eval nltk python-Levenshtein smart-open Theano\n",
            "Installing collected packages: six, urllib3, python-dateutil, jmespath, docutils, idna, certifi, botocore, s3transfer, numpy, boto3, boto, tqdm, torch, smart-open, xdg, waitress, torchtext, Theano, pytz, pyparsing, pyonmttok, psutil, Pillow, nltk, kiwisolver, gensim, cycler, configargparse, Unidecode, torchvision, python-Levenshtein, pandas, OpenNMT-py, nlg-eval, matplotlib, fuzzywuzzy\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.10.8\n",
            "    Uninstalling certifi-2021.10.8:\n",
            "      Successfully uninstalled certifi-2021.10.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 5.2.1\n",
            "    Uninstalling smart-open-5.2.1:\n",
            "      Successfully uninstalled smart-open-5.2.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.6\n",
            "    Uninstalling pyparsing-3.0.6:\n",
            "      Successfully uninstalled pyparsing-3.0.6\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.3.2\n",
            "    Uninstalling kiwisolver-1.3.2:\n",
            "      Successfully uninstalled kiwisolver-1.3.2\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.30.0 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.30.0 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.18.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.1 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.14.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 1.0.1 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.30.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed OpenNMT-py-1.1.1 Pillow-7.0.0 Theano-1.0.5 Unidecode-1.1.1 boto-2.49.0 boto3-1.12.20 botocore-1.15.20 certifi-2019.11.28 configargparse-1.5.3 cycler-0.10.0 docutils-0.15.2 fuzzywuzzy-0.18.0 gensim-3.8.3 idna-2.9 jmespath-0.9.5 kiwisolver-1.1.0 matplotlib-3.2.0 nlg-eval-2.3 nltk-3.4.5 numpy-1.18.1 pandas-1.0.1 psutil-5.9.0 pyonmttok-1.30.0 pyparsing-2.4.6 python-Levenshtein-0.12.0 python-dateutil-2.8.1 pytz-2019.3 s3transfer-0.3.3 six-1.14.0 smart-open-1.9.0 torch-1.4.0 torchtext-0.4.0 torchvision-0.5.0 tqdm-4.30.0 urllib3-1.25.8 waitress-2.0.0 xdg-5.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "cycler",
                  "dateutil",
                  "idna",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas",
                  "psutil",
                  "pyparsing",
                  "pytz",
                  "six",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Datasets"
      ],
      "metadata": {
        "id": "8QUY3iD5Sa0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBzV166rle0u",
        "outputId": "a6111018-b832-4f34-9061-b440f33242c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLjaiUMEjLzj",
        "outputId": "bbd26d9b-8bce-4003-fee4-4aa101af4eb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALL = '/content/drive/My Drive/Data Run'\n",
        "PROCESS = ALL + '/processed'\n",
        "DATA = ALL + \"/question-generator-data\"\n",
        "MODEL = ALL + '/question-generator/models'\n",
        "SRCFILE = ALL + '/question-generator/src/onmt'\n",
        "SAVEFILE = PROCESS + '/onmt'\n",
        "TESTFILE = PROCESS + '/test'\n",
        "WE = MODEL + '/word-embedding'\n",
        "CHKP = MODEL + '/checkpoints'\n",
        "REPORT = MODEL + '/'"
      ],
      "metadata": {
        "id": "-Q5EAUCYo_0R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Repo to Drive (This must be run once only)"
      ],
      "metadata": {
        "id": "SRdbOokYbhhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cd $ALL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeBLlAocbhHq",
        "outputId": "0f3846d0-42e1-464a-d3d3-70b369b518f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Data Run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/FerdiantJoshua/question-generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2aCrjsPb4_A",
        "outputId": "37e22866-a167-4b37-edb0-a06120ad3f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'question-generator'...\n",
            "remote: Enumerating objects: 480, done.\u001b[K\n",
            "remote: Counting objects: 100% (422/422), done.\u001b[K\n",
            "remote: Compressing objects: 100% (243/243), done.\u001b[K\n",
            "remote: Total 480 (delta 254), reused 330 (delta 172), pack-reused 58\u001b[K\n",
            "Receiving objects: 100% (480/480), 47.27 MiB | 12.56 MiB/s, done.\n",
            "Resolving deltas: 100% (273/273), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cp -r /content/question-generator '/content/drive/My Drive/Data Run'"
      ],
      "metadata": {
        "id": "0_qH6ic3cfXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip Tokenizer"
      ],
      "metadata": {
        "id": "fcU_lIat8B7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip \"/content/drive/My Drive/Data Run/ft_to_gl_id_300.vec.zip\""
      ],
      "metadata": {
        "id": "yGKETuNs8BeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce6f043-ad69-491f-a98f-d580305c1c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Data Run/ft_to_gl_id_300.vec.zip\n",
            "  inflating: ft_to_gl_id_300.vec     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cp /content/ft_to_gl_id_300.vec $WE"
      ],
      "metadata": {
        "id": "wADt4FFd7ZIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cd $WE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNh7U-RE_wLP",
        "outputId": "949cbe11-9e00-4a3a-f7f9-be741a652455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/question-generator/models/word-embedding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mv ft_to_gl_id_300.vec ft_to_gl_300_id.vec"
      ],
      "metadata": {
        "id": "uOoQk1L4_blq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation"
      ],
      "metadata": {
        "id": "PRZcyucnSa0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "    import sys\n",
        "    with open(filename, 'r') as f:\n",
        "        contents = f.read()\n",
        "    print (contents)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-21T15:28:13.439110Z",
          "iopub.execute_input": "2022-01-21T15:28:13.439836Z",
          "iopub.status.idle": "2022-01-21T15:28:13.443744Z",
          "shell.execute_reply.started": "2022-01-21T15:28:13.439786Z",
          "shell.execute_reply": "2022-01-21T15:28:13.443092Z"
        },
        "trusted": true,
        "id": "NjfMRW13Sa0z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd $SRCFILE/config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IavTmuQL6gan",
        "outputId": "eb0200c9-8f1c-4811-aef8-5cf02e458eda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Data Run/question-generator/src/onmt/config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read_file(\"gru_045.sh\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-21T15:29:06.966169Z",
          "iopub.execute_input": "2022-01-21T15:29:06.966499Z",
          "iopub.status.idle": "2022-01-21T15:29:06.972540Z",
          "shell.execute_reply.started": "2022-01-21T15:29:06.966459Z",
          "shell.execute_reply": "2022-01-21T15:29:06.971875Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9ClsNtxSa0z",
        "outputId": "f8931724-b467-4556-8729-df36e989638d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#================================================== PREPROCESS ==================================================\n",
            "onmt_preprocess -train_src '$PROCESS/train/squad_id_split0.9_cased_source.txt' -train_tgt '$PROCESS/train/squad_id_split0.9_cased_target.txt' \\\n",
            "    -valid_src '$PROCESS/val/squad_id_split0.9_cased_source.txt' -valid_tgt '$PROCESS/val/squad_id_split0.9_cased_target.txt' \\\n",
            "    -save_data '$SAVEFILE/squad_id_split0.9_cased' \\\n",
            "    -overwrite \\\n",
            "    -dynamic_dict \\\n",
            "    -src_vocab_size 50000 \\\n",
            "    -tgt_vocab_size 30000 \\\n",
            "    -src_seq_length 60 \\\n",
            "    -tgt_seq_length 20\n",
            "\n",
            "#================================================== EMBEDDING ==================================================\n",
            "python '$SRCFILE/embeddings_to_torch.py' -emb_file_both '$WE/ft_to_gl_300_id.vec' \\\n",
            "    -dict_file '$SAVEFILE/squad_id_split0.9_cased.vocab.pt' \\\n",
            "    -output_file '$SAVEFILE/embeddings_cased'\n",
            "\n",
            "#================================================== TRAIN ==================================================\n",
            "onmt_train -data '$SAVEFILE/squad_id_split0.9_cased' -save_model '$CHKP/onmt/gru_045' \\\n",
            "    -world_size 1 -gpu_ranks 0 \\\n",
            "    -seed 42 \\\n",
            "    -save_checkpoint_steps 8025 \\\n",
            "    -word_vec_size 300 \\\n",
            "    -pre_word_vecs_enc '$SAVEFILE/embeddings_cased.enc.pt' \\\n",
            "    -pre_word_vecs_dec '$SAVEFILE/embeddings_cased.dec.pt' \\\n",
            "    -fix_word_vecs_enc \\\n",
            "    -fix_word_vecs_dec \\\n",
            "    -keep_checkpoint 2 \\\n",
            "    -optim 'adam' \\\n",
            "    -learning_rate 0.001 \\\n",
            "    -learning_rate_decay 0.95 \\\n",
            "    -start_decay_steps 16050 \\\n",
            "    -rnn_type GRU \\\n",
            "    -encoder_type brnn \\\n",
            "    -layers 2 \\\n",
            "    -global_attention mlp \\\n",
            "    -rnn_size 256 \\\n",
            "    -train_steps 32100 \\\n",
            "    -valid_steps 3210 \\\n",
            "    -batch_size 64 \\\n",
            "    -dropout 0.3\n",
            "#================================================== TRANSLATE ==================================================\n",
            "#-------------------------------------------------- SQUAD --------------------------------------------------\n",
            "onmt_translate -model '$CHKP/onmt/gru_045_step_32100.pt' \\\n",
            "    -src '$TESTFILE/squad_id_split0.9_cased_source.txt' -output '$MODEL/reports/txts/onmt/gru_045_step_32100_pred.txt' -replace_unk \\\n",
            "    -seed 42 \\\n",
            "    -beam_size 5 \\\n",
            "    -max_length 20\n",
            "\n",
            "#-------------------------------------------------- TYDIQA --------------------------------------------------\n",
            "onmt_translate -model '$CHKP/onmt/gru_045_step_32100.pt' \\\n",
            "    -src '$TESTFILE/tydiqa_id_split0.9_cased_source.txt' -output '$MODEL/reports/txts/onmt/gru_045_step_32100_pred_tydiqa.txt' -replace_unk \\\n",
            "    -seed 42 \\\n",
            "    -beam_size 5 \\\n",
            "    -max_length 20\n",
            "\n",
            "#================================================== EVALUATE ==================================================\n",
            "#-------------------------------------------------- SQUAD --------------------------------------------------\n",
            "python '$SRCFILE/run_evaluation.py' \\\n",
            "    --source_file='$TESTFILE/squad_id_split0.9_cased_source.txt' \\\n",
            "    --target_file='$TESTFILE/squad_id_split0.9_cased_target.txt' \\\n",
            "    --prediction_file='$MODEL/reports/txts/onmt/gru_045_step_32100_pred_tydiqa.txt' \\\n",
            "    --log_file='$MODEL/reports/txts/onmt/eval_log_gru_045_step_32100.txt'\n",
            "\n",
            "#-------------------------------------------------- TYDIQA --------------------------------------------------\n",
            "python '$SRCFILE/run_evaluation.py' \\\n",
            "    --source_file='$TESTFILE/tydiqa_id_split0.9_cased_source.txt' \\\n",
            "    --target_file='$TESTFILE/tydiqa_id_split0.9_cased_target.txt' \\\n",
            "    --prediction_file='$MODEL/reports/txts/onmt/gru_045_step_32100_pred_tydiqa.txt' \\\n",
            "    --log_file='$MODEL/reports/txts/onmt/eval_log_gru_045_step_32100_tydiqa.txt'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.10.0+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po49L9piWp8c",
        "outputId": "548be0fc-11e1-44da-e910-2bc1d4799596"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n",
            "Collecting torch==1.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.6 MB)\n",
            "\u001b[K     |████████████▌                   | 834.1 MB 1.7 MB/s eta 0:12:41tcmalloc: large alloc 1147494400 bytes == 0x5581034b0000 @  0x7fa460255615 0x5580ca1574cc 0x5580ca23747a 0x5580ca15a2ed 0x5580ca24be1d 0x5580ca1cde99 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1cdd00 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca15c039 0x5580ca19f409 0x5580ca15ac52 0x5580ca1cdc25 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9915 0x5580ca15bafa 0x5580ca1c9c0d 0x5580ca1c89ee\n",
            "\u001b[K     |███████████████▉                | 1055.7 MB 1.8 MB/s eta 0:10:16tcmalloc: large alloc 1434370048 bytes == 0x558147b06000 @  0x7fa460255615 0x5580ca1574cc 0x5580ca23747a 0x5580ca15a2ed 0x5580ca24be1d 0x5580ca1cde99 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1cdd00 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca15c039 0x5580ca19f409 0x5580ca15ac52 0x5580ca1cdc25 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9915 0x5580ca15bafa 0x5580ca1c9c0d 0x5580ca1c89ee\n",
            "\u001b[K     |████████████████████            | 1336.2 MB 15.1 MB/s eta 0:00:53tcmalloc: large alloc 1792966656 bytes == 0x5580cc938000 @  0x7fa460255615 0x5580ca1574cc 0x5580ca23747a 0x5580ca15a2ed 0x5580ca24be1d 0x5580ca1cde99 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1cdd00 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca15c039 0x5580ca19f409 0x5580ca15ac52 0x5580ca1cdc25 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9915 0x5580ca15bafa 0x5580ca1c9c0d 0x5580ca1c89ee\n",
            "\u001b[K     |█████████████████████████▎      | 1691.1 MB 51.0 MB/s eta 0:00:09tcmalloc: large alloc 2241208320 bytes == 0x558137720000 @  0x7fa460255615 0x5580ca1574cc 0x5580ca23747a 0x5580ca15a2ed 0x5580ca24be1d 0x5580ca1cde99 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1cdd00 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca24cc66 0x5580ca1c9daf 0x5580ca15c039 0x5580ca19f409 0x5580ca15ac52 0x5580ca1cdc25 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9915 0x5580ca15bafa 0x5580ca1c9c0d 0x5580ca1c89ee\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2137645056 bytes == 0x5581bd082000 @  0x7fa4602541e7 0x5580ca18d067 0x5580ca1574cc 0x5580ca23747a 0x5580ca15a2ed 0x5580ca24be1d 0x5580ca1cde99 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca15bafa 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee\n",
            "tcmalloc: large alloc 2672058368 bytes == 0x5582b0bce000 @  0x7fa460255615 0x5580ca1574cc 0x5580ca23747a 0x5580ca15a2ed 0x5580ca24be1d 0x5580ca1cde99 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1c9c0d 0x5580ca15bafa 0x5580ca1c9c0d 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee 0x5580ca15bbda 0x5580ca1ca737 0x5580ca1c89ee 0x5580ca15c271\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 177 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (3.10.0.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.5.0 requires torch==1.4.0, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESS EX (RUN ONCE ONLY)\n",
        "!onmt_preprocess -train_src '$PROCESS/train/squad_id_split0.9_cased_source.txt' -train_tgt '$PROCESS/train/squad_id_split0.9_cased_target.txt' \\\n",
        "    -valid_src '$PROCESS/val/squad_id_split0.9_cased_source.txt' -valid_tgt '$PROCESS/val/squad_id_split0.9_cased_target.txt' \\\n",
        "    -save_data '$SAVEFILE/squad_id_split0.9_cased' \\\n",
        "    -overwrite \\\n",
        "    -dynamic_dict \\\n",
        "    -src_vocab_size 50000 \\\n",
        "    -tgt_vocab_size 30000 \\\n",
        "    -src_seq_length 60 \\\n",
        "    -tgt_seq_length 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mY8oJK59RiO",
        "outputId": "85b599e1-96dc-4579-fb19-99a85b71eadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-01-23 15:34:37,449 INFO] Extracting features...\n",
            "[2022-01-23 15:34:38,227 INFO]  * number of source features: 3.\n",
            "[2022-01-23 15:34:38,228 INFO]  * number of target features: 0.\n",
            "[2022-01-23 15:34:38,228 INFO] Building `Fields` object...\n",
            "[2022-01-23 15:34:38,228 INFO] Building & saving training data...\n",
            "[2022-01-23 15:34:38,244 WARNING] Shards for corpus train already exist, will be overwritten because `-overwrite` option is set.\n",
            "[2022-01-23 15:34:38,257 WARNING] Overwrite shards for corpus None\n",
            "[2022-01-23 15:34:40,402 INFO] Building shard 0.\n",
            "[2022-01-23 15:35:08,996 INFO]  * saving 0th train data shard to /content/drive/My Drive/Data Run/processed/onmt/squad_id_split0.9_cased.train.0.pt.\n",
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/preprocess.py\", line 101, in process_one_shard\n",
            "    dataset.save(data_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/inputters/dataset_base.py\", line 158, in save\n",
            "    torch.save(self, path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 379, in save\n",
            "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 484, in _save\n",
            "    pickler.dump(obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 467, in persistent_id\n",
            "    if torch.is_storage(obj):\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 733, in next\n",
            "    item = self._items.popleft()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_preprocess\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/preprocess.py\", line 298, in main\n",
            "    preprocess(opt)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/preprocess.py\", line 278, in preprocess\n",
            "    'train', fields, src_reader, tgt_reader, align_reader, opt)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/preprocess.py\", line 203, in build_save_dataset\n",
            "    for sub_counter in p.imap(func, shard_iter):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 737, in next\n",
            "    self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 308, in wait\n",
            "    self._waiters.remove(waiter)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EMBEDDING EX (RUN ONCE ONLY)\n",
        "!python '$SRCFILE/embeddings_to_torch.py' -emb_file_both '$WE/ft_to_gl_300_id.vec' \\\n",
        "    -dict_file '$SAVEFILE/squad_id_split0.9_cased.vocab.pt' \\\n",
        "    -output_file '$SAVEFILE/embeddings_cased'"
      ],
      "metadata": {
        "id": "VgPQ_Y7Z-EbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfccef54-5c7a-41d9-867c-d089a93c11ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-01-23 09:06:02,557 INFO] From: /content/drive/My Drive/Data Run/processed/onmt/squad_id_split0.9_cased.vocab.pt\n",
            "[2022-01-23 09:06:02,557 INFO] \t* source vocab: 50002 words\n",
            "[2022-01-23 09:06:02,557 INFO] \t* target vocab: 30004 words\n",
            "[2022-01-23 09:06:02,569 INFO] Reading encoder and decoder embeddings from /content/question-generator/models/word-embedding/ft_to_gl_300_id.vec\n",
            "[2022-01-23 09:07:20,102 INFO] \tFound 2000000 total vectors in file\n",
            "[2022-01-23 09:07:20,102 INFO] After filtering to vectors in vocab:\n",
            "[2022-01-23 09:07:20,129 INFO] \t* enc: 44875 match, 5127 missing, (89.75%)\n",
            "[2022-01-23 09:07:20,139 INFO] \t* dec: 27654 match, 2350 missing, (92.17%)\n",
            "[2022-01-23 09:07:20,139 INFO] \n",
            "Saving embedding as:\n",
            "\t* enc: /content/drive/My Drive/Data Run/processed/onmt/embeddings_cased.enc.pt\n",
            "\t* dec: /content/drive/My Drive/Data Run/processed/onmt/embeddings_cased.dec.pt\n",
            "[2022-01-23 09:07:21,547 INFO] \n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd $SAVEFILE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMv4QlLxNPaR",
        "outputId": "f3264bfb-9241-4fc7-9fbf-6c1d1307a8e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Data Run/processed/onmt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_82gN2oNQoH",
        "outputId": "c84fe5f4-3562-496e-9e27-7d1a43dbac9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_cased.dec.pt  squad_id_split0.9_cased.train.0.pt\n",
            "embeddings_cased.enc.pt  squad_id_split0.9_cased.valid.0.pt\n",
            "embeddings_to_torch.log  squad_id_split0.9_cased.vocab.pt\n",
            "requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN EX\n",
        "!onmt_train -data '$SAVEFILE/squad_id_split0.9_cased' -save_model '$CHKP/onmt/gru_043' \\\n",
        "    -world_size 1 -gpu_ranks 0 \\\n",
        "    -seed 42 \\\n",
        "    -save_checkpoint_steps 8025 \\\n",
        "    -word_vec_size 300 \\\n",
        "    -pre_word_vecs_enc '$SAVEFILE/embeddings_cased.enc.pt' \\\n",
        "    -pre_word_vecs_dec '$SAVEFILE/embeddings_cased.dec.pt' \\\n",
        "    -fix_word_vecs_enc \\\n",
        "    -fix_word_vecs_dec \\\n",
        "    -keep_checkpoint 2 \\\n",
        "    -optim 'adam' \\\n",
        "    -learning_rate 0.001 \\\n",
        "    -learning_rate_decay 0.95 \\\n",
        "    -start_decay_steps 16050 \\\n",
        "    -rnn_type GRU \\\n",
        "    -encoder_type brnn \\\n",
        "    -layers 2 \\\n",
        "    -global_attention mlp \\\n",
        "    -rnn_size 256 \\\n",
        "    -train_steps 32100 \\\n",
        "    -valid_steps 3210 \\\n",
        "    -batch_size 64 \\\n",
        "    -dropout 0.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkS8t4FtANEz",
        "outputId": "bf2efffd-433e-4b5a-ac52-a91bc268c9a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-01-24 14:01:09,353 INFO]  * src vocab size = 50002\n",
            "[2022-01-24 14:01:09,353 INFO]  * src_feat_0 vocab size = 4\n",
            "[2022-01-24 14:01:09,353 INFO]  * src_feat_1 vocab size = 21\n",
            "[2022-01-24 14:01:09,353 INFO]  * src_feat_2 vocab size = 27\n",
            "[2022-01-24 14:01:09,353 INFO]  * tgt vocab size = 30004\n",
            "[2022-01-24 14:01:09,353 INFO] Building model...\n",
            "[2022-01-24 14:01:12,861 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50002, 300, padding_idx=1)\n",
            "          (1): Embedding(4, 2, padding_idx=1)\n",
            "          (2): Embedding(21, 8, padding_idx=1)\n",
            "          (3): Embedding(27, 10, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (rnn): GRU(320, 128, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(30004, 300, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "    (rnn): StackedGRU(\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): GRUCell(556, 256)\n",
            "        (1): GRUCell(256, 256)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_context): Linear(in_features=256, out_features=256, bias=False)\n",
            "      (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
            "      (linear_out): Linear(in_features=512, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=30004, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2022-01-24 14:01:12,861 INFO] encoder: 15643094\n",
            "[2022-01-24 14:01:12,861 INFO] decoder: 17995044\n",
            "[2022-01-24 14:01:12,862 INFO] * number of parameters: 33638138\n",
            "[2022-01-24 14:01:12,866 INFO] Starting training on GPU: [0]\n",
            "[2022-01-24 14:01:12,866 INFO] Start training loop and validate every 3210 steps...\n",
            "[2022-01-24 14:01:12,866 INFO] Loading dataset from /content/drive/My Drive/Data Run/processed/onmt/squad_id_split0.9_cased.train.0.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_train\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/train.py\", line 206, in main\n",
            "    train(opt)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/train.py\", line 88, in train\n",
            "    single_main(opt, 0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/train_single.py\", line 143, in main\n",
            "    valid_steps=opt.valid_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/trainer.py\", line 246, in train\n",
            "    self._accum_batches(train_iter)):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/trainer.py\", line 184, in _accum_batches\n",
            "    for batch in iterator:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/inputters/inputter.py\", line 822, in __iter__\n",
            "    for batch in self._iter_dataset(path):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/inputters/inputter.py\", line 788, in _iter_dataset\n",
            "    cur_dataset = torch.load(path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 607, in load\n",
            "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 878, in _load\n",
            "    data_file = io.BytesIO(zip_file.get_record(pickle_file))\n",
            "RuntimeError: PytorchStreamReader failed locating file data.pkl: file not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd $MODEL/reports/txts/onmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WtD8xCba_53",
        "outputId": "1c582b93-af5c-4ad7-aed1-e1788bd82a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Data Run/question-generator/models/reports/txts/onmt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86EW4trsbBUc",
        "outputId": "d541104f-3bd3-4fe3-8c7e-0364b142f426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval_log_gru_043_step_32100.txt  gru_043_step_32100_pred_tydiqa.txt\n",
            "gru_043_step_32100_pred.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenNMT-py==1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T3i5PvBmEuJ",
        "outputId": "9800c984-f259-4682-9bbc-e73ea253fc0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py==1.2\n",
            "  Downloading OpenNMT_py-1.2.0-py3-none-any.whl (195 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▊                              | 10 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 195 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: configargparse in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (4.30.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (2.0.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (1.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (1.14.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (0.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (3.13)\n",
            "Collecting torchtext==0.4.0\n",
            "  Using cached torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (2.7.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (1.10.0+cu111)\n",
            "Requirement already satisfied: pyonmttok==1.* in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2) (1.30.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2) (1.18.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (1.43.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2) (1.25.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2) (3.1.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->OpenNMT-py==1.2) (2.0.1)\n",
            "Installing collected packages: torchtext, OpenNMT-py\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.5.0\n",
            "    Uninstalling torchtext-0.5.0:\n",
            "      Successfully uninstalled torchtext-0.5.0\n",
            "  Attempting uninstall: OpenNMT-py\n",
            "    Found existing installation: OpenNMT-py 2.2.0\n",
            "    Uninstalling OpenNMT-py-2.2.0:\n",
            "      Successfully uninstalled OpenNMT-py-2.2.0\n",
            "Successfully installed OpenNMT-py-1.2.0 torchtext-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TESTFILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzsqmJ6KAg4V",
        "outputId": "ff35f442-903c-44bc-a30b-7a2d29784cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Data Run/processed/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRANSLATE EX\n",
        "#SQUAD\n",
        "!onmt_translate -model '$CHKP/onmt/gru_043_step_32100.pt' \\\n",
        "    -src '$TESTFILE/squad_id_split0.9_cased_source.txt' -output '$MODEL/reports/txts/onmt/gru_043_step_32100_pred.txt' -replace_unk \\\n",
        "    -seed 42 \\\n",
        "    -beam_size 5 \\\n",
        "    -max_length 20\n",
        "\n",
        "# TYDIQA \n",
        "!onmt_translate -model '$CHKP/onmt/gru_043_step_32100.pt' \\\n",
        "    -src '$TESTFILE/tydiqa_id_split0.9_cased_source.txt' -output '$MODEL/reports/txts/onmt/gru_043_step_32100_pred_tydiqa.txt' -replace_unk \\\n",
        "    -seed 42 \\\n",
        "    -beam_size 5 \\\n",
        "    -max_length 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5XODIZ3BtFq",
        "outputId": "334361aa-7339-4d37-b167-f272ac7cab16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-01-23 15:44:26,119 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:212: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "[2022-01-23 15:52:58,259 INFO] PRED AVG SCORE: -0.7332, PRED PPL: 2.0816\n",
            "[2022-01-23 15:52:58,321 INFO] Translating shard 1.\n",
            "[2022-01-23 16:01:22,743 INFO] PRED AVG SCORE: -0.7283, PRED PPL: 2.0716\n",
            "[2022-01-23 16:01:22,814 INFO] Translating shard 2.\n",
            "[2022-01-23 16:09:47,502 INFO] PRED AVG SCORE: -0.7226, PRED PPL: 2.0598\n",
            "[2022-01-23 16:09:47,569 INFO] Translating shard 3.\n",
            "[2022-01-23 16:18:20,220 INFO] PRED AVG SCORE: -0.7196, PRED PPL: 2.0536\n",
            "[2022-01-23 16:18:20,289 INFO] Translating shard 4.\n",
            "[2022-01-23 16:26:48,669 INFO] PRED AVG SCORE: -0.7309, PRED PPL: 2.0770\n",
            "[2022-01-23 16:26:48,736 INFO] Translating shard 5.\n",
            "[2022-01-23 16:35:15,683 INFO] PRED AVG SCORE: -0.7343, PRED PPL: 2.0840\n",
            "[2022-01-23 16:35:15,751 INFO] Translating shard 6.\n",
            "[2022-01-23 16:43:47,340 INFO] PRED AVG SCORE: -0.7598, PRED PPL: 2.1378\n",
            "[2022-01-23 16:43:47,407 INFO] Translating shard 7.\n",
            "[2022-01-23 16:52:15,937 INFO] PRED AVG SCORE: -0.7234, PRED PPL: 2.0615\n",
            "[2022-01-23 16:52:16,006 INFO] Translating shard 8.\n",
            "[2022-01-23 17:00:48,973 INFO] PRED AVG SCORE: -0.7346, PRED PPL: 2.0846\n",
            "[2022-01-23 17:00:49,050 INFO] Translating shard 9.\n",
            "[2022-01-23 17:08:58,568 INFO] PRED AVG SCORE: -0.7458, PRED PPL: 2.1082\n",
            "[2022-01-23 17:08:58,635 INFO] Translating shard 10.\n",
            "[2022-01-23 17:17:19,177 INFO] PRED AVG SCORE: -0.7336, PRED PPL: 2.0826\n",
            "[2022-01-23 17:17:19,240 INFO] Translating shard 11.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [140], which does not match the required output shape [28, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "[2022-01-23 17:22:20,541 INFO] PRED AVG SCORE: -0.7416, PRED PPL: 2.0993\n",
            "[2022-01-23 17:22:24,849 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:212: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [80], which does not match the required output shape [16, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "[2022-01-23 17:22:50,726 INFO] PRED AVG SCORE: -0.7099, PRED PPL: 2.0338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(SRCFILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLTag4vQmlIF",
        "outputId": "154a43d5-c0c8-4bf4-8931-6e87425fa48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Data Run/question-generator/src/onmt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE EX\n",
        "# SQUAD \n",
        "!python '$SRCFILE/run_evaluation.py' \\\n",
        "    --source_file='$TESTFILE/squad_id_split0.9_cased_source.txt' \\\n",
        "    --target_file='$TESTFILE/squad_id_split0.9_cased_target.txt' \\\n",
        "    --prediction_file='$MODEL/reports/txts/onmt/gru_043_step_32100_pred.txt' \\\n",
        "    --log_file='$MODEL/reports/txts/onmt/eval_log_gru_043_step_32100.txt'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjZuwKr-JnVH",
        "outputId": "05a66a4f-9be7-40ce-b0d7-c572accfe849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 11.38s\n",
            "500: 13.05s\n",
            "1000: 13.93s\n",
            "1500: 14.69s\n",
            "2000: 15.46s\n",
            "2500: 16.32s\n",
            "3000: 17.13s\n",
            "3500: 17.93s\n",
            "4000: 18.71s\n",
            "4500: 19.43s\n",
            "5000: 20.13s\n",
            "5500: 20.73s\n",
            "6000: 21.27s\n",
            "6500: 21.80s\n",
            "7000: 22.32s\n",
            "7500: 22.99s\n",
            "8000: 23.68s\n",
            "8500: 24.20s\n",
            "9000: 24.70s\n",
            "9500: 25.35s\n",
            "10000: 25.93s\n",
            "10500: 26.51s\n",
            "11000: 27.00s\n",
            "11500: 27.61s\n",
            "12000: 28.24s\n",
            "12500: 28.84s\n",
            "13000: 29.44s\n",
            "13500: 29.98s\n",
            "14000: 30.47s\n",
            "14500: 30.97s\n",
            "15000: 31.52s\n",
            "15500: 31.99s\n",
            "16000: 32.46s\n",
            "16500: 33.01s\n",
            "17000: 33.51s\n",
            "17500: 34.00s\n",
            "18000: 34.48s\n",
            "18500: 34.97s\n",
            "19000: 35.51s\n",
            "19500: 35.96s\n",
            "20000: 36.46s\n",
            "20500: 36.93s\n",
            "21000: 37.44s\n",
            "21500: 37.91s\n",
            "22000: 38.38s\n",
            "22500: 38.92s\n",
            "23000: 39.39s\n",
            "23500: 39.86s\n",
            "24000: 40.33s\n",
            "24500: 40.83s\n",
            "25000: 41.28s\n",
            "25500: 41.79s\n",
            "26000: 42.33s\n",
            "26500: 42.84s\n",
            "27000: 43.50s\n",
            "27500: 43.98s\n",
            "28000: 44.49s\n",
            "28500: 44.97s\n",
            "29000: 45.44s\n",
            "29500: 45.95s\n",
            "30000: 46.43s\n",
            "30500: 46.91s\n",
            "31000: 47.39s\n",
            "31500: 47.87s\n",
            "32000: 48.33s\n",
            "32500: 48.82s\n",
            "33000: 49.35s\n",
            "33500: 49.84s\n",
            "34000: 50.29s\n",
            "34500: 50.76s\n",
            "35000: 51.22s\n",
            "35500: 51.71s\n",
            "36000: 52.20s\n",
            "36500: 52.67s\n",
            "37000: 53.18s\n",
            "37500: 53.65s\n",
            "38000: 54.12s\n",
            "38500: 54.59s\n",
            "39000: 55.08s\n",
            "39500: 55.55s\n",
            "40000: 56.05s\n",
            "40500: 56.60s\n",
            "41000: 57.09s\n",
            "41500: 57.55s\n",
            "42000: 58.02s\n",
            "42500: 58.50s\n",
            "43000: 58.99s\n",
            "43500: 59.45s\n",
            "44000: 59.96s\n",
            "44500: 60.42s\n",
            "45000: 60.90s\n",
            "45500: 61.36s\n",
            "46000: 61.83s\n",
            "46500: 62.33s\n",
            "47000: 62.80s\n",
            "47500: 63.37s\n",
            "48000: 64.00s\n",
            "48500: 64.53s\n",
            "49000: 65.01s\n",
            "49500: 65.50s\n",
            "50000: 65.99s\n",
            "50500: 66.45s\n",
            "51000: 66.99s\n",
            "51500: 67.47s\n",
            "52000: 67.95s\n",
            "52500: 68.43s\n",
            "53000: 68.90s\n",
            "53500: 69.38s\n",
            "54000: 69.85s\n",
            "54500: 70.32s\n",
            "55000: 70.80s\n",
            "55500: 71.28s\n",
            "56000: 71.77s\n",
            "56500: 72.26s\n",
            "57000: 72.72s\n",
            "57500: 73.20s\n",
            "58000: 73.68s\n",
            "58500: 74.15s\n",
            "59000: 74.62s\n",
            "59500: 75.07s\n",
            "60000: 75.53s\n",
            "60500: 75.99s\n",
            "61000: 76.47s\n",
            "61500: 76.92s\n",
            "62000: 77.40s\n",
            "62500: 77.85s\n",
            "63000: 78.29s\n",
            "63500: 78.81s\n",
            "64000: 79.40s\n",
            "64500: 79.85s\n",
            "65000: 80.36s\n",
            "65500: 80.85s\n",
            "66000: 81.35s\n",
            "66500: 81.82s\n",
            "67000: 82.32s\n",
            "67500: 82.84s\n",
            "68000: 83.30s\n",
            "68500: 83.78s\n",
            "69000: 84.26s\n",
            "69500: 84.75s\n",
            "70000: 85.22s\n",
            "70500: 85.72s\n",
            "71000: 86.18s\n",
            "71500: 86.65s\n",
            "72000: 87.13s\n",
            "72500: 87.63s\n",
            "73000: 88.10s\n",
            "73500: 88.61s\n",
            "74000: 89.09s\n",
            "74500: 89.58s\n",
            "75000: 90.09s\n",
            "75500: 90.58s\n",
            "76000: 91.05s\n",
            "76500: 91.53s\n",
            "77000: 92.04s\n",
            "77500: 92.51s\n",
            "78000: 93.06s\n",
            "78500: 93.54s\n",
            "79000: 94.02s\n",
            "79500: 94.49s\n",
            "80000: 94.99s\n",
            "80500: 95.47s\n",
            "81000: 95.93s\n",
            "81500: 96.44s\n",
            "82000: 96.91s\n",
            "82500: 97.37s\n",
            "83000: 97.87s\n",
            "83500: 98.35s\n",
            "84000: 98.83s\n",
            "84500: 99.31s\n",
            "85000: 99.79s\n",
            "85500: 100.27s\n",
            "86000: 100.78s\n",
            "86500: 101.27s\n",
            "87000: 101.76s\n",
            "87500: 102.25s\n",
            "88000: 102.71s\n",
            "88500: 103.19s\n",
            "89000: 103.68s\n",
            "89500: 104.19s\n",
            "90000: 104.68s\n",
            "90500: 105.14s\n",
            "91000: 105.61s\n",
            "91500: 106.08s\n",
            "92000: 106.58s\n",
            "92500: 107.06s\n",
            "93000: 107.53s\n",
            "93500: 108.01s\n",
            "94000: 108.48s\n",
            "94500: 108.95s\n",
            "95000: 109.44s\n",
            "95500: 109.90s\n",
            "96000: 110.38s\n",
            "96500: 110.86s\n",
            "97000: 111.35s\n",
            "97500: 111.84s\n",
            "98000: 112.31s\n",
            "98500: 112.77s\n",
            "99000: 113.27s\n",
            "99500: 113.77s\n",
            "100000: 114.27s\n",
            "100500: 114.77s\n",
            "101000: 115.27s\n",
            "101500: 115.76s\n",
            "102000: 116.25s\n",
            "102500: 116.73s\n",
            "103000: 117.21s\n",
            "103500: 117.69s\n",
            "104000: 118.16s\n",
            "104500: 118.64s\n",
            "105000: 119.12s\n",
            "105500: 119.61s\n",
            "106000: 120.11s\n",
            "106500: 120.62s\n",
            "107000: 121.10s\n",
            "107500: 121.58s\n",
            "108000: 122.05s\n",
            "108500: 122.54s\n",
            "109000: 123.04s\n",
            "109500: 123.53s\n",
            "110000: 124.02s\n",
            "110500: 124.51s\n",
            "111000: 125.01s\n",
            "111500: 125.52s\n",
            "112000: 126.01s\n",
            "112500: 126.49s\n",
            "113000: 126.97s\n",
            "113500: 127.47s\n",
            "114000: 127.97s\n",
            "114500: 128.43s\n",
            "115000: 128.92s\n",
            "115500: 129.41s\n",
            "{'Bleu_1': 0.4146, 'Bleu_2': 0.2619, 'Bleu_3': 0.1663, 'Bleu_4': 0.1059, 'METEOR': 0.2284, 'ROUGE_L': 0.4739, 'Bleu_avg': 0.2372}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TYDIQA \n",
        "!python '$SRCFILE/run_evaluation.py' \\\n",
        "    --source_file='$TESTFILE/tydiqa_id_split0.9_cased_source.txt' \\\n",
        "    --target_file='$TESTFILE/tydiqa_id_split0.9_cased_target.txt' \\\n",
        "    --prediction_file='$MODEL/reports/txts/onmt/gru_043_step_32100_pred_tydiqa.txt' \\\n",
        "    --log_file='$MODEL/reports/txts/onmt/eval_log_gru_043_step_32100_tydiqa.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D73Y3hp-zua",
        "outputId": "a6c60d94-860f-4dd4-8e10-b275229febff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 11.22s\n",
            "500: 12.65s\n",
            "{'Bleu_1': 0.3516, 'Bleu_2': 0.1612, 'Bleu_3': 0.0858, 'Bleu_4': 0.0423, 'METEOR': 0.1805, 'ROUGE_L': 0.3926, 'Bleu_avg': 0.1602}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VCC7hP-kfAA7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}